---
title: "STAT 333 Project Two"
Author1: "Xinyi Yu  xyu286@wisc.edu"
Author2:  "Xiu Xie   @wisc.edu"
Authour3: "Yuhan Xie   xie75@wisc.edu"  
Author4: "Yuwen Zhang  zhang924@wisc.edu"
date: 04/20/2019
output: html_document
---


```{r}
library(readr)
library(stringr)

rm(list = ls())
chart = read_csv("train_Madison.csv")
origin_data = chart
#head(chart)
```

```{r}
chart = origin_data

#pos_new = scan("new_words.txt", what = character())

data_transform = function(data = chart, test = FALSE, portion = TRUE, create = TRUE, origin = chart) {
  #data = chart
  #test = FALSE
  #portion = TRUE
  #create = TRUE
  data = data[colnames(data) != "chicago" & colnames(data) != "wisconsin"]
  colnames(data)[colnames(data) == "name"] = "NAME"
  colnames(data)[colnames(data) == "city"] = "CITY"
  colnames(data)[colnames(data) == "text"] = "TEXT"
  colnames(data)[colnames(data) == "star"] = "STAR"
  if(create == TRUE){
    data = data[1:which(colnames(data) == "nword")]
    if(test == TRUE){
      for(i in (which(colnames(origin) == "nword")+1):length(origin)){
        data$new_col = rep(0, nrow(data))
        colnames(data)[ncol(data)] = colnames(origin)[i]
      }
    }
  }
  if(create == FALSE){
    data$disgust = rep(0, nrow(data))
    data$hate = rep(0, nrow(data))
    data$zero = rep(0, nrow(data))
  }
  
  data$exclam = rep(0, nrow(data))
  data$question = rep(0, nrow(data))
  data$fivestar = rep(0, nrow(data))
  data$dots_count = rep(0, nrow(data))
  data$capital = rep(0, nrow(data))
  for(i in 1:nrow(data)){
    if(i%%1000 == 0){
      print(i)
      if(test == FALSE){
        delete_index = c()
        for(j in (which(colnames(data) == "nword")+1):length(data)){
          if(sum(data[j]) < 0.01*i)
            delete_index = c(delete_index, j)
        }
        data = data[-delete_index]
        print(length(data))
      }
    }
    
    text = data$TEXT[i]
    #---------------------------
    if(create == TRUE && test == FALSE){
      words = str_extract_all(tolower(text), "[a-z]+")
      for(j in 1:length(words[[1]])){
        if(!(words[[1]][j] %in% colnames(data))){
          data$new_col = rep(0, nrow(data))
          data$new_col[i] = 1
          colnames(data)[ncol(data)] = words[[1]][j]
        }else{
          data[i, which(colnames(data) == words[[1]][j])] = data[i, which(colnames(data) == words[[1]][j])] + 1
        }
      }
    }
    if(create == TRUE && test == TRUE){
      words = str_extract_all(tolower(text), "[a-z]+")
      for(j in 1:length(words[[1]])){
        if(words[[1]][j] %in% colnames(origin)){
          if(!(words[[1]][j] %in% colnames(data))){
            data$new_col = rep(0, nrow(data))
            data$new_col[i] = 1
            colnames(data)[ncol(data)] = words[[1]][j]
          }else{
            data[i, which(colnames(data) == words[[1]][j])] = data[i, which(colnames(data) == words[[1]][j])] + 1
          }
        }
      }
    }
    if(create == FALSE){
      data$disgust[i] = str_count(tolower(text), pattern = "disgust")
      
      data$hate[i] = str_count(tolower(text), pattern = "hate")
      data$zero[i] = str_count(tolower(text), pattern = "zero")
    }
    
    #count punctuations=
    data$exclam[i] = str_count(text, pattern = "!")
    data$question[i] = str_count(text, pattern = "\\?")
    data$fivestar[i] = str_count(text, pattern = "5 star")
    data$dots_count[i] = str_count(text, pattern = "\\.")
    data$capital[i] = str_count(text, pattern = "[ABCDEFGHIJKLMNOPQRSTUVWXYZ]")
  }
  
  
  #find the most influencial predictors
  if(test == TRUE){
    trim = ((which(colnames(data) == "nword"))+1):length(data)
    predictor_data = origin[((which(colnames(origin) == "nword"))+1):length(origin)]
  }
  else{
    trim = ((which(colnames(data) == "nword"))+1):length(data)
    predictor_data = data[trim]
  }
  l<-rep(0, length(predictor_data)) #cor of each predictor with star
  for (i in 1:length(predictor_data)){
    if(test == TRUE){
      l[i] = cor(origin$star, predictor_data[,i])
    }
    else{
      l[i] = cor(data$star, predictor_data[,i])
    }
  }
  most = names(predictor_data[order(l) < 51])
  least = names(predictor_data[order(l) > (length(l) - 51)])
  #calculate the number of extreme words
  most_sum = apply(data[,most], MARGIN = 1, FUN = sum)
  least_sum = apply(data[,least], MARGIN = 1, FUN = sum)
  
  not_important = names(predictor_data[order(l) < length(l)-100 & order(l) > 100])
  #-----------------------
  
  data$portion = (most_sum+1) / (least_sum+1)
  
  
  #transform all count of words to portion of text
  if(portion == TRUE){
    data[trim] = data[trim] / data$nword
  }
  return(data)
}

transformed_data = data_transform(chart, portion = TRUE)
trim = (which(colnames(transformed_data) == "nchar")):length(transformed_data)
#head(transformed_data)
transformed_data[,(length(transformed_data) - 50):length(transformed_data)]
chart = transformed_data
transformed_data$portion
```


```{r}
model1 = lm(star ~ . , data = chart[c(2,trim)])
#summary(model1)$coefficients[-1,4]
yhat = predict(model1)
yhat[yhat > 5] = 5
yhat[yhat < 1] = 1
resid = chart$star - yhat
SSE = sum(resid^2)
SSE
summary(model1)$p_value
plot(chart$Id, resid, xlab = "ID", ylab = "Residuals", main = "Residual Plot",pch = 23,bg = "red",cex = 1.2)
abline(a = 0, b = 0, col = "black", lwd = 3)
sortResid = sort(abs(resid), decreasing = TRUE)
Outlier = sortResid[1:100]
Outlier
```
  
```{r}
par(mfrow = c(1,2))
hist(resid, breaks = 100, main="Histogram of Residuals", xlab = "Residuals")
plot(density(resid), main="Kernel Density of Residuals", xlab = "Residuals")
```

```{r}
coefSum = rep(0, ncol(chart[trim]))
interSum = 0
count = 0

for (i in 1:100){
  list = sample(x = 1:nrow(chart), size = 10000)
  model.random = lm(star ~ ., data = chart[list, c(2, trim)])
  if(length(summary(model.random)$coefficients[-1,1]) == length(trim)){
    coefSum = coefSum + summary(model.random)$coefficients[-1,1]
    interSum = interSum + summary(model.random)$coefficients[1,1]
    count = count + 1
  }
  else{
    tail(summary(model.random))
  }
}
fitRaw = data.matrix(chart[trim]) %*% data.matrix(coefSum/count)
fitRaw = fitRaw + interSum/count
fitRaw[fitRaw > 5] = 5
fitRaw[fitRaw < 1] = 1
residNew = chart$star - fitRaw
SSENew = sum(residNew^2)
SSENew
#model1 = lm(star ~ ., data = rawdata)
#summary(model1)
#trim = which(summary(model1)$coefficients[,4] < 1)
#model2 = lm(star ~ ., data = rawdata[trim])
#summary(model2)

```


```{r}
test_data = read_csv("test_Madison.csv")
test_transformed = data_transform(test_data[1:100,], portion = TRUE, test = TRUE, origin = transformed_data)
write.csv(test_transformed, "test_1917_predictor.csv", row.names = FALSE)
test_data = test_transformed
trim = (which(colnames(test_data) == "nchar")):length(test_data)
```

```{r}
fit_data = data.matrix(test_data[trim]) %*% data.matrix(coefSum/count)
fit_data = fit_data + interSum/count
fit_data[fit_data > 5] = 5
fit_data[fit_data < 1] = 1
result = as.data.frame(test_data[,1])
colnames(result)[1] = "Id"
result$Expected = fit_data
result
write.csv(result, "test_result.csv", row.names = FALSE)
```
